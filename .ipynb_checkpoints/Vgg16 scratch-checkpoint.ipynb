{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(path):\n",
    "    x_train=[]\n",
    "    y_train=[]\n",
    "    label = 0\n",
    "    for labels in os.listdir(path):\n",
    "        if labels == 'ka':\n",
    "            label = 0\n",
    "        elif labels == 'ca':\n",
    "            label = 1\n",
    "        elif labels == 'ta':\n",
    "            label = 2\n",
    "        elif labels == 'pa':\n",
    "            label = 3\n",
    "        elif labels == 'ya':\n",
    "            label = 4\n",
    "        elif labels == 'wa':\n",
    "            label = 5\n",
    "        elif labels == 'ga':\n",
    "            label = 6\n",
    "        elif labels == 'ja':\n",
    "            label = 7\n",
    "        elif labels == 'da':\n",
    "            label = 8\n",
    "        elif labels == 'ba':\n",
    "            label = 9\n",
    "        elif labels == 'ra':\n",
    "            label = 10\n",
    "        elif labels == 'sa':\n",
    "            label = 11\n",
    "        elif labels == 'nga':\n",
    "            label = 12\n",
    "        elif labels == 'nya':\n",
    "            label = 13\n",
    "        elif labels == 'na':\n",
    "            label = 14\n",
    "        elif labels == 'ma':\n",
    "            label = 15\n",
    "        elif labels == 'la':\n",
    "            label = 16\n",
    "        elif labels== 'ha':\n",
    "            label = 17\n",
    "            \n",
    "        all_images_path=glob.glob(path+labels+'/*.jpg')\n",
    "        for img_path in all_images_path :\n",
    "                img=load_img(img_path, target_size=(32,32))\n",
    "                img=img_to_array(img)\n",
    "                img=img/255.0\n",
    "                x_train.append(img)\n",
    "                y_train.append(label)\n",
    "    return np.array(x_train),np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = prepare_dataset('train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = prepare_dataset('test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Flatten()(pretrained_model.output)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)                  \n",
    "x = layers.Dense(18, activation='softmax')(x)           \n",
    "\n",
    "model_vgg = Model(pretrained_model.input, x) \n",
    "\n",
    "\n",
    "model_vgg.compile(optimizer = Adam(lr=0.0001), \n",
    "              loss = 'sparse_categorical_crossentropy', \n",
    "              metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model_vgg.fit(x_train,y_train,epochs=7,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skripsi",
   "language": "python",
   "name": "skripsi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
