{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(path):\n",
    "    x_train=[]\n",
    "    y_train=[]\n",
    "    label = 0\n",
    "    for labels in os.listdir(path):\n",
    "        if labels == 'ka':\n",
    "            label = 0\n",
    "        elif labels == 'ca':\n",
    "            label = 1\n",
    "        elif labels == 'ta':\n",
    "            label = 2\n",
    "        elif labels == 'pa':\n",
    "            label = 3\n",
    "        elif labels == 'ya':\n",
    "            label = 4\n",
    "        elif labels == 'wa':\n",
    "            label = 5\n",
    "        elif labels == 'ga':\n",
    "            label = 6\n",
    "        elif labels == 'ja':\n",
    "            label = 7\n",
    "        elif labels == 'da':\n",
    "            label = 8\n",
    "        elif labels == 'ba':\n",
    "            label = 9\n",
    "        elif labels == 'ra':\n",
    "            label = 10\n",
    "        elif labels == 'sa':\n",
    "            label = 11\n",
    "        elif labels == 'nga':\n",
    "            label = 12\n",
    "        elif labels == 'nya':\n",
    "            label = 13\n",
    "        elif labels == 'na':\n",
    "            label = 14\n",
    "        elif labels == 'ma':\n",
    "            label = 15\n",
    "        elif labels == 'la':\n",
    "            label = 16\n",
    "        elif labels== 'ha':\n",
    "            label = 17\n",
    "            \n",
    "        all_images_path=glob.glob(path+labels+'/*.jpg')\n",
    "        for img_path in all_images_path :\n",
    "                img=load_img(img_path, target_size=(32,32))\n",
    "                img=img_to_array(img)\n",
    "                img=img/255.0\n",
    "                x_train.append(img)\n",
    "                y_train.append(label)\n",
    "    return np.array(x_train),np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = prepare_dataset('train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = prepare_dataset('test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "local_weights_file = 'D:/Belajar/skripsi/ngalegena/pretrained/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "pretrained_model=VGG16(input_shape = (32, 32, 3), \n",
    "                        include_top = False, \n",
    "                        weights =None)\n",
    "\n",
    "pretrained_model.load_weights(local_weights_file)\n",
    "for layer in pretrained_model.layers:\n",
    "     layer.trainable = False\n",
    "        \n",
    "pretrained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Flatten()(pretrained_model.output)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)                  \n",
    "x = layers.Dense(18, activation='softmax')(x)           \n",
    "\n",
    "model_vgg = Model(pretrained_model.input, x) \n",
    "\n",
    "\n",
    "model_vgg.compile(optimizer = Adam(lr=0.0001), \n",
    "              loss = 'sparse_categorical_crossentropy', \n",
    "              metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3780 samples, validate on 1620 samples\n",
      "Epoch 1/10\n",
      "3780/3780 [==============================] - 15s 4ms/sample - loss: 0.4874 - acc: 0.8616 - val_loss: 0.4948 - val_acc: 0.8630\n",
      "Epoch 2/10\n",
      "3780/3780 [==============================] - 15s 4ms/sample - loss: 0.4816 - acc: 0.8577 - val_loss: 0.4869 - val_acc: 0.8605\n",
      "Epoch 3/10\n",
      "3780/3780 [==============================] - 15s 4ms/sample - loss: 0.4655 - acc: 0.8688 - val_loss: 0.4779 - val_acc: 0.8617\n",
      "Epoch 4/10\n",
      "3780/3780 [==============================] - 15s 4ms/sample - loss: 0.4612 - acc: 0.8656 - val_loss: 0.4763 - val_acc: 0.8642\n",
      "Epoch 5/10\n",
      "3780/3780 [==============================] - 15s 4ms/sample - loss: 0.4620 - acc: 0.8648 - val_loss: 0.4694 - val_acc: 0.8642\n",
      "Epoch 6/10\n",
      "3780/3780 [==============================] - 15s 4ms/sample - loss: 0.4503 - acc: 0.8630 - val_loss: 0.4664 - val_acc: 0.8660\n",
      "Epoch 7/10\n",
      "3780/3780 [==============================] - 15s 4ms/sample - loss: 0.4454 - acc: 0.8667 - val_loss: 0.4581 - val_acc: 0.8630\n",
      "Epoch 8/10\n",
      "3780/3780 [==============================] - 15s 4ms/sample - loss: 0.4285 - acc: 0.8746 - val_loss: 0.4544 - val_acc: 0.8642\n",
      "Epoch 9/10\n",
      "3780/3780 [==============================] - 15s 4ms/sample - loss: 0.4356 - acc: 0.8696 - val_loss: 0.4463 - val_acc: 0.8685\n",
      "Epoch 10/10\n",
      "3780/3780 [==============================] - 15s 4ms/sample - loss: 0.4322 - acc: 0.8720 - val_loss: 0.4415 - val_acc: 0.8735\n"
     ]
    }
   ],
   "source": [
    "history=model_vgg.fit(x_train,y_train,epochs=10,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skripsi",
   "language": "python",
   "name": "skripsi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
